import os
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt

# Upload the file
uploaded = files.upload()
filename = list(uploaded.keys())[0]
df = pd.read_csv(filename)

# Create the output directory if it doesn't exist
output_dir = './outputs/RandomForest_Fast'
os.makedirs(output_dir, exist_ok=True)

# Select only the specified input features
selected_features = ['game_id', 'completion_rate', 'revisit_frequency', 'time_spent_same_domain', 'content_same_domain']
X = data[selected_features]

# Group the output features into 3 groups
group1_cols = [f'game_{i:03d}' for i in range(1, 11)]  # game_001 to game_010
group2_cols = [f'game_{i:03d}' for i in range(11, 21)]  # game_011 to game_020
group3_cols = [f'game_{i:03d}' for i in range(21, 31)]  # game_021 to game_030

y_group1 = data[group1_cols]
y_group2 = data[group2_cols]
y_group3 = data[group3_cols]

print(f"Input features shape: {X.shape}")
print(f"Group 1 output shape: {y_group1.shape}")
print(f"Group 2 output shape: {y_group2.shape}")
print(f"Group 3 output shape: {y_group3.shape}")

# Normalize the input features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Define the RandomForest model with fixed parameters for speed
rf_model = RandomForestRegressor(
    random_state=42, 
    n_estimators=50,       # Reduced for speed
    max_depth=10,
    min_samples_split=5,
    min_samples_leaf=2,
    n_jobs=-1
)

# Function to train and evaluate model for each group (no hyperparameter tuning)
def train_evaluate_group_fast(X_scaled, y_group, group_name):
    print(f"\nTraining {group_name}...")
    
    # Split the dataset into training and testing sets (80-20 split)
    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_group, test_size=0.2, random_state=42)
    
    # Create a fresh model for each group
    model = RandomForestRegressor(
        random_state=42, 
        n_estimators=50,
        max_depth=10,
        min_samples_split=5,
        min_samples_leaf=2,
        n_jobs=-1
    )
    
    # Train the model
    model.fit(X_train, y_train)
    
    # Make predictions on the test set
    y_pred = model.predict(X_test)
    
    # Calculate RMSE and R²
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    r2 = r2_score(y_test, y_pred)
    
    print(f'{group_name} - RMSE: {rmse:.4f}, R²: {r2:.4f}')
    
    return model, X_test, y_test, y_pred, rmse, r2

# Train models for each group
print("=== TRAINING MODELS ===")
model_group1, X_test_1, y_test_1, y_pred_1, rmse_1, r2_1 = train_evaluate_group_fast(X_scaled, y_group1, "Group 1 (Games 1-10)")
model_group2, X_test_2, y_test_2, y_pred_2, rmse_2, r2_2 = train_evaluate_group_fast(X_scaled, y_group2, "Group 2 (Games 11-20)")
model_group3, X_test_3, y_test_3, y_pred_3, rmse_3, r2_3 = train_evaluate_group_fast(X_scaled, y_group3, "Group 3 (Games 21-30)")

# Print summary results
print("\n=== SUMMARY RESULTS ===")
print(f"Group 1 (Games 1-10)  - RMSE: {rmse_1:.4f}, R²: {r2_1:.4f}")
print(f"Group 2 (Games 11-20) - RMSE: {rmse_2:.4f}, R²: {r2_2:.4f}")
print(f"Group 3 (Games 21-30) - RMSE: {rmse_3:.4f}, R²: {r2_3:.4f}")

# Create visualization for all three groups
fig, axes = plt.subplots(1, 3, figsize=(18, 5))

groups_data = [
    (y_test_1, y_pred_1, "Group 1 (Games 1-10)", rmse_1, r2_1),
    (y_test_2, y_pred_2, "Group 2 (Games 11-20)", rmse_2, r2_2),
    (y_test_3, y_pred_3, "Group 3 (Games 21-30)", rmse_3, r2_3)
]

for idx, (y_test, y_pred, title, rmse, r2) in enumerate(groups_data):
    # Use the first column of each group for visualization
    y_test_col = y_test.iloc[:, 0]
    y_pred_col = y_pred[:, 0]
    
    # Scatter plot
    axes[idx].scatter(y_test_col, y_pred_col, alpha=0.6, s=50, c='blue')
    
    # Plot diagonal line (y = x) for reference
    min_val = min(y_test_col.min(), y_pred_col.min())
    max_val = max(y_test_col.max(), y_pred_col.max())
    axes[idx].plot([min_val, max_val], [min_val, max_val], 'r--', lw=2)
    
    # Set plot title and labels
    axes[idx].set_title(f'{title}\nRMSE: {rmse:.4f}, R²: {r2:.4f}', fontsize=12)
    axes[idx].set_xlabel('Actual Values', fontsize=10)
    axes[idx].set_ylabel('Predicted Values', fontsize=10)
    axes[idx].grid(True, linestyle='--', alpha=0.7)

plt.tight_layout()
plt.savefig(os.path.join(output_dir, 'fast_predictions_comparison.png'), dpi=300, bbox_inches='tight')
plt.show()

# Plot feature importance for all three groups
fig, axes = plt.subplots(1, 3, figsize=(18, 5))

models = [model_group1, model_group2, model_group3]
group_names = ["Group 1 (Games 1-10)", "Group 2 (Games 11-20)", "Group 3 (Games 21-30)"]

for idx, (model, group_name) in enumerate(zip(models, group_names)):
    # Get feature importance
    feature_importances = model.feature_importances_
    
    # Create bar plot
    bars = axes[idx].bar(selected_features, feature_importances)
    axes[idx].set_title(f'Feature Importance - {group_name}', fontsize=12)
    axes[idx].set_ylabel('Importance', fontsize=10)
    axes[idx].tick_params(axis='x', rotation=45)
    
    # Add value labels on bars
    for bar, importance in zip(bars, feature_importances):
        axes[idx].text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.001,
                      f'{importance:.3f}', ha='center', va='bottom', fontsize=9)

plt.tight_layout()
plt.savefig(os.path.join(output_dir, 'fast_feature_importance.png'), dpi=300, bbox_inches='tight')
plt.show()

# Create RMSE and R² bar charts
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))

# RMSE Bar Chart
groups = ['Group 1\n(Games 1-10)', 'Group 2\n(Games 11-20)', 'Group 3\n(Games 21-30)']
rmse_values = [rmse_1, rmse_2, rmse_3]
colors = ['#ff6b6b', '#ffd93d', '#6bcf7f']  # Red, Yellow, Green

bars1 = ax1.bar(groups, rmse_values, color=colors)
ax1.set_title('RMSE by Group', fontsize=14, fontweight='bold')
ax1.set_ylabel('RMSE', fontsize=12)
ax1.set_ylim(0, max(rmse_values) * 1.1)

# Add value labels on RMSE bars
for bar, value in zip(bars1, rmse_values):
    ax1.text(bar.get_x() + bar.get_width()/2., bar.get_height() + max(rmse_values)*0.01,
             f'{value:.3f}', ha='center', va='bottom', fontsize=11, fontweight='bold')

# R² Bar Chart
r2_values = [r2_1, r2_2, r2_3]

bars2 = ax2.bar(groups, r2_values, color=colors)
ax2.set_title('R² Score by Group', fontsize=14, fontweight='bold')
ax2.set_ylabel('R² Score', fontsize=12)
ax2.set_ylim(0, 1.0)  # Set y-axis to go from 0 to 1.0 for R² scores

# Add value labels on R² bars
for bar, value in zip(bars2, r2_values):
    ax2.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.01,
             f'{value:.3f}', ha='center', va='bottom', fontsize=11, fontweight='bold')

plt.tight_layout()
plt.savefig(os.path.join(output_dir, 'rmse_r2_comparison.png'), dpi=300, bbox_inches='tight')
plt.show()

# Create a summary table of results
results_summary = pd.DataFrame({
    'Group': ['Group 1 (Games 1-10)', 'Group 2 (Games 11-20)', 'Group 3 (Games 21-30)'],
    'RMSE': [rmse_1, rmse_2, rmse_3],
    'R²': [r2_1, r2_2, r2_3],
    'Output_Games': ['game_001 to game_010', 'game_011 to game_020', 'game_021 to game_030']
})

print("\n=== RESULTS SUMMARY TABLE ===")
print(results_summary.to_string(index=False))

# Save results summary to CSV
results_summary.to_csv(os.path.join(output_dir, 'fast_results_summary.csv'), index=False)

print(f"\nAll outputs saved to: {output_dir}")
print("Files generated:")
print("- fast_predictions_comparison.png")
print("- fast_feature_importance.png")
print("- rmse_r2_comparison.png") 
print("- decision_trees_sample.png")
print("- feature_importance_comparison.png")
print("- oob_scores.png")
print("- residuals_analysis.png")
print("- learning_curves.png")
print("- fast_results_summary.csv")

print("\n=== MODEL PARAMETERS USED ===")
print("n_estimators: 50")
print("max_depth: 10")
print("min_samples_split: 5")
print("min_samples_leaf: 2")
print("No hyperparameter tuning (for speed)")

# Additional Random Forest Visualizations
print("\n=== CREATING ADDITIONAL VISUALIZATIONS ===")

# 1. Tree Visualization (first tree from each forest)
from sklearn.tree import plot_tree

fig, axes = plt.subplots(1, 3, figsize=(20, 8))
models = [model_group1, model_group2, model_group3]
group_names = ["Group 1 (Games 1-10)", "Group 2 (Games 11-20)", "Group 3 (Games 21-30)"]

for idx, (model, group_name) in enumerate(zip(models, group_names)):
    # Plot the first tree from the random forest
    plot_tree(model.estimators_[0], 
              feature_names=selected_features, 
              max_depth=3,  # Limit depth for readability
              filled=True, 
              ax=axes[idx],
              fontsize=8)
    axes[idx].set_title(f'First Decision Tree - {group_name}', fontsize=12, fontweight='bold')

plt.tight_layout()
plt.savefig(os.path.join(output_dir, 'decision_trees_sample.png'), dpi=300, bbox_inches='tight')
plt.show()

# 2. Feature Importance Comparison (All Groups in One Chart)
fig, ax = plt.subplots(figsize=(12, 6))

x = np.arange(len(selected_features))
width = 0.25

# Get feature importances for all groups
importance_group1 = model_group1.feature_importances_
importance_group2 = model_group2.feature_importances_
importance_group3 = model_group3.feature_importances_

# Create grouped bar chart
bars1 = ax.bar(x - width, importance_group1, width, label='Group 1', color='#ff6b6b', alpha=0.8)
bars2 = ax.bar(x, importance_group2, width, label='Group 2', color='#ffd93d', alpha=0.8)
bars3 = ax.bar(x + width, importance_group3, width, label='Group 3', color='#6bcf7f', alpha=0.8)

ax.set_title('Feature Importance Comparison Across All Groups', fontsize=14, fontweight='bold')
ax.set_ylabel('Importance', fontsize=12)
ax.set_xlabel('Features', fontsize=12)
ax.set_xticks(x)
ax.set_xticklabels(selected_features, rotation=45, ha='right')
ax.legend()
ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig(os.path.join(output_dir, 'feature_importance_comparison.png'), dpi=300, bbox_inches='tight')
plt.show()

# 3. Out-of-Bag (OOB) Score Analysis
print("\n=== OUT-OF-BAG SCORE ANALYSIS ===")

# Create models with OOB scoring enabled
oob_models = []
oob_scores = []

for i, (y_group, group_name) in enumerate([(y_group1, "Group 1"), (y_group2, "Group 2"), (y_group3, "Group 3")]):
    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_group, test_size=0.2, random_state=42)
    
    oob_model = RandomForestRegressor(
        random_state=42, 
        n_estimators=50,
        max_depth=10,
        min_samples_split=5,
        min_samples_leaf=2,
        oob_score=True,  # Enable OOB scoring
        n_jobs=-1
    )
    
    oob_model.fit(X_train, y_train)
    oob_models.append(oob_model)
    oob_scores.append(oob_model.oob_score_)
    print(f"{group_name} OOB Score: {oob_model.oob_score_:.4f}")

# 4. OOB Score Visualization
fig, ax = plt.subplots(figsize=(8, 6))

bars = ax.bar(groups, oob_scores, color=colors)
ax.set_title('Out-of-Bag (OOB) Scores by Group', fontsize=14, fontweight='bold')
ax.set_ylabel('OOB Score', fontsize=12)
ax.set_ylim(0, 1.0)

# Add value labels on bars
for bar, score in zip(bars, oob_scores):
    ax.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.01,
            f'{score:.3f}', ha='center', va='bottom', fontsize=11, fontweight='bold')

plt.tight_layout()
plt.savefig(os.path.join(output_dir, 'oob_scores.png'), dpi=300, bbox_inches='tight')
plt.show()

# 5. Residuals Analysis
fig, axes = plt.subplots(1, 3, figsize=(18, 5))

for idx, (y_test, y_pred, title) in enumerate([(y_test_1, y_pred_1, "Group 1"), 
                                               (y_test_2, y_pred_2, "Group 2"), 
                                               (y_test_3, y_pred_3, "Group 3")]):
    # Calculate residuals (for first output variable of each group)
    residuals = y_test.iloc[:, 0] - y_pred[:, 0]
    
    # Create residual plot
    axes[idx].scatter(y_pred[:, 0], residuals, alpha=0.6, s=30)
    axes[idx].axhline(y=0, color='red', linestyle='--', linewidth=2)
    axes[idx].set_title(f'Residuals Plot - {title}', fontsize=12, fontweight='bold')
    axes[idx].set_xlabel('Predicted Values', fontsize=10)
    axes[idx].set_ylabel('Residuals', fontsize=10)
    axes[idx].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig(os.path.join(output_dir, 'residuals_analysis.png'), dpi=300, bbox_inches='tight')
plt.show()

# 6. Learning Curves (Training vs Validation Error)
from sklearn.model_selection import validation_curve

print("\n=== GENERATING LEARNING CURVES ===")

# Test different numbers of estimators
n_estimators_range = [10, 25, 50, 75, 100, 150, 200]

fig, axes = plt.subplots(1, 3, figsize=(18, 5))

for idx, (y_group, group_name) in enumerate([(y_group1, "Group 1"), (y_group2, "Group 2"), (y_group3, "Group 3")]):
    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_group, test_size=0.2, random_state=42)
    
    train_scores, val_scores = validation_curve(
        RandomForestRegressor(random_state=42, max_depth=10),
        X_train, y_train,
        param_name='n_estimators',
        param_range=n_estimators_range,
        cv=3,  # 3-fold CV for speed
        scoring='neg_mean_squared_error',
        n_jobs=-1
    )
    
    # Convert to positive values and take square root for RMSE
    train_rmse = np.sqrt(-train_scores)
    val_rmse = np.sqrt(-val_scores)
    
    train_rmse_mean = np.mean(train_rmse, axis=1)
    train_rmse_std = np.std(train_rmse, axis=1)
    val_rmse_mean = np.mean(val_rmse, axis=1)
    val_rmse_std = np.std(val_rmse, axis=1)
    
    axes[idx].plot(n_estimators_range, train_rmse_mean, 'o-', color='blue', label='Training RMSE')
    axes[idx].fill_between(n_estimators_range, train_rmse_mean - train_rmse_std,
                          train_rmse_mean + train_rmse_std, alpha=0.1, color='blue')
    
    axes[idx].plot(n_estimators_range, val_rmse_mean, 'o-', color='red', label='Validation RMSE')
    axes[idx].fill_between(n_estimators_range, val_rmse_mean - val_rmse_std,
                          val_rmse_mean + val_rmse_std, alpha=0.1, color='red')
    
    axes[idx].set_title(f'Learning Curve - {group_name}', fontsize=12, fontweight='bold')
    axes[idx].set_xlabel('Number of Estimators', fontsize=10)
    axes[idx].set_ylabel('RMSE', fontsize=10)
    axes[idx].legend()
    axes[idx].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig(os.path.join(output_dir, 'learning_curves.png'), dpi=300, bbox_inches='tight')
plt.show()
