# Import necessary libraries
import os
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt

# Upload the file
uploaded = files.upload()
filename = list(uploaded.keys())[0]
df = pd.read_csv(filename)

# Select only the specified input features
selected_features = ['game_id', 'completion_rate', 'revisit_frequency', 'time_spent_same_domain', 'content_same_domain']
X = data[selected_features]

# Group the output features into 3 groups
group1_cols = [f'game_{i:03d}' for i in range(1, 11)]  # game_001 to game_010
group2_cols = [f'game_{i:03d}' for i in range(11, 21)]  # game_011 to game_020
group3_cols = [f'game_{i:03d}' for i in range(21, 31)]  # game_021 to game_030

y_group1 = data[group1_cols]
y_group2 = data[group2_cols]
y_group3 = data[group3_cols]

print(f"Input features shape: {X.shape}")
print(f"Group 1 output shape: {y_group1.shape}")
print(f"Group 2 output shape: {y_group2.shape}")
print(f"Group 3 output shape: {y_group3.shape}")

# Normalize the input features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Define the RandomForest model with fixed parameters for speed
rf_model = RandomForestRegressor(
    random_state=42, 
    n_estimators=50,       # Reduced for speed
    max_depth=10,
    min_samples_split=5,
    min_samples_leaf=2,
    n_jobs=-1
)

# Function to train and evaluate model for each group (no hyperparameter tuning)
def train_evaluate_group_fast(X_scaled, y_group, group_name):
    print(f"\nTraining {group_name}...")
    
    # Split the dataset into training and testing sets (80-20 split)
    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_group, test_size=0.2, random_state=42)
    
    # Create a fresh model for each group
    model = RandomForestRegressor(
        random_state=42, 
        n_estimators=50,
        max_depth=10,
        min_samples_split=5,
        min_samples_leaf=2,
        n_jobs=-1
    )
    
    # Train the model
    model.fit(X_train, y_train)
    
    # Make predictions on the test set
    y_pred = model.predict(X_test)
    
    # Calculate RMSE and R²
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    r2 = r2_score(y_test, y_pred)
    
    print(f'{group_name} - RMSE: {rmse:.4f}, R²: {r2:.4f}')
    
    return model, X_test, y_test, y_pred, rmse, r2

# Train models for each group
print("=== TRAINING MODELS ===")
model_group1, X_test_1, y_test_1, y_pred_1, rmse_1, r2_1 = train_evaluate_group_fast(X_scaled, y_group1, "Group 1 (Games 1-10)")
model_group2, X_test_2, y_test_2, y_pred_2, rmse_2, r2_2 = train_evaluate_group_fast(X_scaled, y_group2, "Group 2 (Games 11-20)")
model_group3, X_test_3, y_test_3, y_pred_3, rmse_3, r2_3 = train_evaluate_group_fast(X_scaled, y_group3, "Group 3 (Games 21-30)")

# Print summary results
print("\n=== SUMMARY RESULTS ===")
print(f"Group 1 (Games 1-10)  - RMSE: {rmse_1:.4f}, R²: {r2_1:.4f}")
print(f"Group 2 (Games 11-20) - RMSE: {rmse_2:.4f}, R²: {r2_2:.4f}")
print(f"Group 3 (Games 21-30) - RMSE: {rmse_3:.4f}, R²: {r2_3:.4f}")

# Create visualization for all three groups
fig, axes = plt.subplots(1, 3, figsize=(18, 5))

groups_data = [
    (y_test_1, y_pred_1, "Group 1 (Games 1-10)", rmse_1, r2_1),
    (y_test_2, y_pred_2, "Group 2 (Games 11-20)", rmse_2, r2_2),
    (y_test_3, y_pred_3, "Group 3 (Games 21-30)", rmse_3, r2_3)
]

for idx, (y_test, y_pred, title, rmse, r2) in enumerate(groups_data):
    # Use the first column of each group for visualization
    y_test_col = y_test.iloc[:, 0]
    y_pred_col = y_pred[:, 0]
    
    # Scatter plot
    axes[idx].scatter(y_test_col, y_pred_col, alpha=0.6, s=50, c='blue')
    
    # Plot diagonal line (y = x) for reference
    min_val = min(y_test_col.min(), y_pred_col.min())
    max_val = max(y_test_col.max(), y_pred_col.max())
    axes[idx].plot([min_val, max_val], [min_val, max_val], 'r--', lw=2)
    
    # Set plot title and labels
    axes[idx].set_title(f'{title}\nRMSE: {rmse:.4f}, R²: {r2:.4f}', fontsize=12)
    axes[idx].set_xlabel('Actual Values', fontsize=10)
    axes[idx].set_ylabel('Predicted Values', fontsize=10)
    axes[idx].grid(True, linestyle='--', alpha=0.7)

plt.tight_layout()
plt.savefig(os.path.join(output_dir, 'fast_predictions_comparison.png'), dpi=300, bbox_inches='tight')
plt.show()

# Plot feature importance for all three groups
fig, axes = plt.subplots(1, 3, figsize=(18, 5))

models = [model_group1, model_group2, model_group3]
group_names = ["Group 1 (Games 1-10)", "Group 2 (Games 11-20)", "Group 3 (Games 21-30)"]

for idx, (model, group_name) in enumerate(zip(models, group_names)):
    # Get feature importance
    feature_importances = model.feature_importances_
    
    # Create bar plot
    bars = axes[idx].bar(selected_features, feature_importances)
    axes[idx].set_title(f'Feature Importance - {group_name}', fontsize=12)
    axes[idx].set_ylabel('Importance', fontsize=10)
    axes[idx].tick_params(axis='x', rotation=45)
    
    # Add value labels on bars
    for bar, importance in zip(bars, feature_importances):
        axes[idx].text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.001,
                      f'{importance:.3f}', ha='center', va='bottom', fontsize=9)

plt.tight_layout()
plt.savefig(os.path.join(output_dir, 'fast_feature_importance.png'), dpi=300, bbox_inches='tight')
plt.show()

# Create a summary table of results
results_summary = pd.DataFrame({
    'Group': ['Group 1 (Games 1-10)', 'Group 2 (Games 11-20)', 'Group 3 (Games 21-30)'],
    'RMSE': [rmse_1, rmse_2, rmse_3],
    'R²': [r2_1, r2_2, r2_3],
    'Output_Games': ['game_001 to game_010', 'game_011 to game_020', 'game_021 to game_030']
})

print("\n=== RESULTS SUMMARY TABLE ===")
print(results_summary.to_string(index=False))

# Save results summary to CSV
results_summary.to_csv(os.path.join(output_dir, 'fast_results_summary.csv'), index=False)

print(f"\nAll outputs saved to: {output_dir}")
print("Files generated:")
print("- fast_predictions_comparison.png")
print("- fast_feature_importance.png") 
print("- fast_results_summary.csv")

print("\n=== MODEL PARAMETERS USED ===")
print("n_estimators: 50")
print("max_depth: 10")
print("min_samples_split: 5")
print("min_samples_leaf: 2")
print("No hyperparameter tuning (for speed)")
